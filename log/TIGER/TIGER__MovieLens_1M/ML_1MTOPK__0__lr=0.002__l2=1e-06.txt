INFO:root:Namespace(model_name='TIGER', model_mode='')
INFO:root:--------------------------------------------- BEGIN: 2025-12-05 10:32:16 ---------------------------------------------
INFO:root:
=============================================
 Arguments            | Values               
=============================================
 batch_size           | 512                 
 beam_size            | 30                  
 codebook_k           | 256                 
 d_ff                 | 1024                
 d_kv                 | 64                  
 d_model              | 128                 
 data_appendix        |                     
 dataset              | MovieLens_1M/ML_1...
 dropout              | 0                   
 dropout_rate         | 0.1                 
 early_stop           | 10                  
 eos_token_id         | 0                   
 epoch                | 100                 
 eval_batch_size      | 128                 
 feed_forward_proj    | relu                
 gpu                  | 0                   
 history_max          | 20                  
 l2                   | 1e-06               
 lr                   | 0.002               
 main_metric          |                     
 max_len              | 20                  
 num_codebooks        | 4                   
 num_decoder_layers   | 4                   
 num_heads            | 6                   
 num_layers           | 2                   
 num_neg              | 1                   
 num_workers          | 5                   
 optimizer            | Adam                
 pad_token_id         | 0                   
 random_seed          | 0                   
 save_converted_codes | 1                   
 save_final_results   | 1                   
 test_all             | 0                   
 tiger_code_path      |                     
 topk                 | 5,10,20,50          
 vocab_size           | 1025                
=============================================
INFO:root:Device: cuda
INFO:root:Load corpus from ../data/MovieLens_1M/ML_1MTOPK/TIGERReader.pkl
INFO:root:TIGER: using corpus.item_codes already present
INFO:root:#params: 3941888
INFO:root:TIGER(
  (model): T5ForConditionalGeneration(
    (shared): Embedding(3127, 128)
    (encoder): T5Stack(
      (embed_tokens): Embedding(3127, 128)
      (block): ModuleList(
        (0): T5Block(
          (layer): ModuleList(
            (0): T5LayerSelfAttention(
              (SelfAttention): T5Attention(
                (q): Linear(in_features=128, out_features=384, bias=False)
                (k): Linear(in_features=128, out_features=384, bias=False)
                (v): Linear(in_features=128, out_features=384, bias=False)
                (o): Linear(in_features=384, out_features=128, bias=False)
                (relative_attention_bias): Embedding(32, 6)
              )
              (layer_norm): FusedRMSNorm(torch.Size([128]), eps=1e-06, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): T5LayerFF(
              (DenseReluDense): T5DenseActDense(
                (wi): Linear(in_features=128, out_features=1024, bias=False)
                (wo): Linear(in_features=1024, out_features=128, bias=False)
                (dropout): Dropout(p=0.1, inplace=False)
                (act): ReLU()
              )
              (layer_norm): FusedRMSNorm(torch.Size([128]), eps=1e-06, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
        (1): T5Block(
          (layer): ModuleList(
            (0): T5LayerSelfAttention(
              (SelfAttention): T5Attention(
                (q): Linear(in_features=128, out_features=384, bias=False)
                (k): Linear(in_features=128, out_features=384, bias=False)
                (v): Linear(in_features=128, out_features=384, bias=False)
                (o): Linear(in_features=384, out_features=128, bias=False)
              )
              (layer_norm): FusedRMSNorm(torch.Size([128]), eps=1e-06, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): T5LayerFF(
              (DenseReluDense): T5DenseActDense(
                (wi): Linear(in_features=128, out_features=1024, bias=False)
                (wo): Linear(in_features=1024, out_features=128, bias=False)
                (dropout): Dropout(p=0.1, inplace=False)
                (act): ReLU()
              )
              (layer_norm): FusedRMSNorm(torch.Size([128]), eps=1e-06, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (final_layer_norm): FusedRMSNorm(torch.Size([128]), eps=1e-06, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (decoder): T5Stack(
      (embed_tokens): Embedding(3127, 128)
      (block): ModuleList(
        (0): T5Block(
          (layer): ModuleList(
            (0): T5LayerSelfAttention(
              (SelfAttention): T5Attention(
                (q): Linear(in_features=128, out_features=384, bias=False)
                (k): Linear(in_features=128, out_features=384, bias=False)
                (v): Linear(in_features=128, out_features=384, bias=False)
                (o): Linear(in_features=384, out_features=128, bias=False)
                (relative_attention_bias): Embedding(32, 6)
              )
              (layer_norm): FusedRMSNorm(torch.Size([128]), eps=1e-06, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): T5LayerCrossAttention(
              (EncDecAttention): T5Attention(
                (q): Linear(in_features=128, out_features=384, bias=False)
                (k): Linear(in_features=128, out_features=384, bias=False)
                (v): Linear(in_features=128, out_features=384, bias=False)
                (o): Linear(in_features=384, out_features=128, bias=False)
              )
              (layer_norm): FusedRMSNorm(torch.Size([128]), eps=1e-06, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): T5LayerFF(
              (DenseReluDense): T5DenseActDense(
                (wi): Linear(in_features=128, out_features=1024, bias=False)
                (wo): Linear(in_features=1024, out_features=128, bias=False)
                (dropout): Dropout(p=0.1, inplace=False)
                (act): ReLU()
              )
              (layer_norm): FusedRMSNorm(torch.Size([128]), eps=1e-06, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
        (1-3): 3 x T5Block(
          (layer): ModuleList(
            (0): T5LayerSelfAttention(
              (SelfAttention): T5Attention(
                (q): Linear(in_features=128, out_features=384, bias=False)
                (k): Linear(in_features=128, out_features=384, bias=False)
                (v): Linear(in_features=128, out_features=384, bias=False)
                (o): Linear(in_features=384, out_features=128, bias=False)
              )
              (layer_norm): FusedRMSNorm(torch.Size([128]), eps=1e-06, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): T5LayerCrossAttention(
              (EncDecAttention): T5Attention(
                (q): Linear(in_features=128, out_features=384, bias=False)
                (k): Linear(in_features=128, out_features=384, bias=False)
                (v): Linear(in_features=128, out_features=384, bias=False)
                (o): Linear(in_features=384, out_features=128, bias=False)
              )
              (layer_norm): FusedRMSNorm(torch.Size([128]), eps=1e-06, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (2): T5LayerFF(
              (DenseReluDense): T5DenseActDense(
                (wi): Linear(in_features=128, out_features=1024, bias=False)
                (wo): Linear(in_features=1024, out_features=128, bias=False)
                (dropout): Dropout(p=0.1, inplace=False)
                (act): ReLU()
              )
              (layer_norm): FusedRMSNorm(torch.Size([128]), eps=1e-06, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (final_layer_norm): FusedRMSNorm(torch.Size([128]), eps=1e-06, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (lm_head): Linear(in_features=128, out_features=3127, bias=False)
  )
)
INFO:root:Test Before Training: (HR@5:0.0518,NDCG@5:0.0334,HR@10:0.0957,NDCG@10:0.0475,HR@20:0.1893,NDCG@20:0.0708,HR@50:0.5045,NDCG@50:0.1322)
INFO:root:Optimizer: Adam
INFO:root:Epoch 1     loss=3.2084 [37.6 s]	dev=(HR@5:0.0769,NDCG@5:0.0459) [17.0 s] *
INFO:root:Epoch 2     loss=1.3812 [37.5 s]	dev=(HR@5:0.0769,NDCG@5:0.0455) [17.2 s]
INFO:root:Epoch 3     loss=1.3672 [37.4 s]	dev=(HR@5:0.0753,NDCG@5:0.0467) [17.0 s] *
INFO:root:Epoch 4     loss=1.3632 [37.4 s]	dev=(HR@5:0.0773,NDCG@5:0.0479) [17.6 s] *
INFO:root:Epoch 5     loss=1.3600 [37.2 s]	dev=(HR@5:0.0800,NDCG@5:0.0474) [17.0 s]
INFO:root:Epoch 6     loss=1.3542 [37.5 s]	dev=(HR@5:0.0812,NDCG@5:0.0464) [17.1 s]
INFO:root:Epoch 7     loss=1.3476 [37.5 s]	dev=(HR@5:0.0847,NDCG@5:0.0517) [17.2 s] *
INFO:root:Epoch 8     loss=1.3422 [37.3 s]	dev=(HR@5:0.0808,NDCG@5:0.0479) [17.3 s]
INFO:root:Epoch 9     loss=1.3359 [37.3 s]	dev=(HR@5:0.0909,NDCG@5:0.0548) [17.0 s] *
INFO:root:Epoch 10    loss=1.3300 [37.4 s]	dev=(HR@5:0.0890,NDCG@5:0.0529) [17.0 s]
INFO:root:Epoch 11    loss=1.3250 [37.5 s]	dev=(HR@5:0.0964,NDCG@5:0.0573) [17.1 s] *
INFO:root:Epoch 12    loss=1.3211 [37.4 s]	dev=(HR@5:0.1050,NDCG@5:0.0626) [17.4 s] *
INFO:root:Epoch 13    loss=1.3171 [37.3 s]	dev=(HR@5:0.1003,NDCG@5:0.0599) [17.3 s]
INFO:root:Epoch 14    loss=1.3133 [37.3 s]	dev=(HR@5:0.1011,NDCG@5:0.0597) [17.2 s]
INFO:root:Epoch 15    loss=1.3102 [37.4 s]	dev=(HR@5:0.0937,NDCG@5:0.0570) [17.1 s]
INFO:root:Epoch 16    loss=1.3075 [37.4 s]	dev=(HR@5:0.1066,NDCG@5:0.0639) [17.0 s] *
INFO:root:Epoch 17    loss=1.3052 [37.3 s]	dev=(HR@5:0.1046,NDCG@5:0.0612) [17.1 s]
INFO:root:Epoch 18    loss=1.3033 [37.5 s]	dev=(HR@5:0.0999,NDCG@5:0.0612) [17.3 s]
INFO:root:Epoch 19    loss=1.3012 [37.4 s]	dev=(HR@5:0.0976,NDCG@5:0.0588) [17.5 s]
INFO:root:Epoch 20    loss=1.2993 [37.2 s]	dev=(HR@5:0.1093,NDCG@5:0.0662) [17.2 s] *
INFO:root:Epoch 21    loss=1.2975 [37.3 s]	dev=(HR@5:0.1163,NDCG@5:0.0682) [17.0 s] *
INFO:root:Epoch 22    loss=1.2960 [37.4 s]	dev=(HR@5:0.0976,NDCG@5:0.0572) [17.5 s]
INFO:root:Epoch 23    loss=1.2945 [37.4 s]	dev=(HR@5:0.1034,NDCG@5:0.0609) [17.3 s]
INFO:root:Epoch 24    loss=1.2933 [37.3 s]	dev=(HR@5:0.1003,NDCG@5:0.0596) [17.3 s]
INFO:root:Epoch 25    loss=1.2918 [37.2 s]	dev=(HR@5:0.1034,NDCG@5:0.0633) [17.7 s]
INFO:root:Epoch 26    loss=1.2908 [37.3 s]	dev=(HR@5:0.1034,NDCG@5:0.0624) [17.0 s]
INFO:root:Epoch 27    loss=1.2896 [37.2 s]	dev=(HR@5:0.1030,NDCG@5:0.0626) [17.0 s]
INFO:root:Epoch 28    loss=1.2888 [37.2 s]	dev=(HR@5:0.1077,NDCG@5:0.0660) [17.0 s]
INFO:root:Epoch 29    loss=1.2874 [37.1 s]	dev=(HR@5:0.1112,NDCG@5:0.0653) [17.4 s]
INFO:root:Epoch 30    loss=1.2864 [37.2 s]	dev=(HR@5:0.1038,NDCG@5:0.0625) [17.2 s]
INFO:root:Early stop at 30 based on dev result.
INFO:root:
Best Iter(dev)=   21	 dev=(HR@5:0.1163,NDCG@5:0.0682) [1637.4 s] 
INFO:root:Load model from ../model/TIGER/TIGER__MovieLens_1M/ML_1MTOPK__0__lr=0.002__l2=1e-06.pt
INFO:root:
Dev  After Training: (HR@5:0.1163,NDCG@5:0.0682,HR@10:0.1842,NDCG@10:0.0899,HR@20:0.3224,NDCG@20:0.1246,HR@50:0.6440,NDCG@50:0.1879)
INFO:root:
Test After Training: (HR@5:0.1141,NDCG@5:0.0706,HR@10:0.2029,NDCG@10:0.0992,HR@20:0.3417,NDCG@20:0.1341,HR@50:0.6545,NDCG@50:0.1957)
INFO:root:Saving top-100 recommendation results to: ../log/TIGER/TIGER__MovieLens_1M/ML_1MTOPK__0__lr=0/rec-TIGER-dev.csv
INFO:root:dev Prediction results saved!
INFO:root:Saving top-100 recommendation results to: ../log/TIGER/TIGER__MovieLens_1M/ML_1MTOPK__0__lr=0/rec-TIGER-test.csv
INFO:root:test Prediction results saved!
INFO:root:
--------------------------------------------- END: 2025-12-05 11:01:10 ---------------------------------------------
